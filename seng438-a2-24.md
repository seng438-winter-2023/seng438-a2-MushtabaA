**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#2 – Requirements-Based Test Generation**

| Group \#:      |  24   |
| -------------- | --- |
| Student Names: |  Ahad Ali   |
|                |  Mushtaba Al Yasseen   |
|                |  Parbir Lehal   |
|                |  Athul Rajagopal   |

# 1 Introduction

The objective of this lab is to obtain hands-on experience with unit testing and black box testing using technologies such as JUnit and JMock. Prior to the lab, we were introduced to these two testing methodologies, and the rationale behind them. Unit testing refers to the testing of individual units or components of a software system. The goal of unit testing is to validate that each unit of the software system is working as intended, independently of the other units. On the other hand, black box testing is solely concerned with the inputs and outputs of a system-under-test (SUT). The goal of black box testing is to validate that the system meets its functional requirements. The two methodologies can be, and should be used together, as their intended outcomes complement one another. To develop an effective test suite, strategies such as equivalence class partitioning and boundary value analysis are used. Using a combination of these testing procedures, we were able to visualize the distinct purposes of each, and further understand their unique advantages and disadvantages.


# 2 Detailed description of unit test strategy

### Input Partitions: Range Class Methods

#### `contains(double value)` ####
Spec. 1
* value does not exist (Invalid)
* value does exist (Valid)

Spec. 2
* value is lower bound (Valid)
* value is upper bound (Valid)

Spec. 3
* value is a negative number (Valid)
* value is a positive number (Valid)

#### `getLength(double value)` ####
Spec. 1
* range length is 0 (Valid)
* range length is greater than 0 (Valid)

Spec. 2
* only lower bound is decimal (Valid)
* only upper bound is decimal (Valid)
* both bounds are decimal (Valid)
* both bounds are whole number (Valid)

Spec. 3
* only upper bound is positive (Valid)
* both bounds are positive (Valid)
* both bounds are negative (Valid)


#### `upperBoundRange():` ####
Spec 1:
* double data Range contains positive values (valid) 
* double data Range negative values (valid) 
* double data Range contains positive and negative values (valid)

Spec 2:
* double data same range (valid) 

Spec 3:
* double data Max and Min Range values (valid)

#### `constrain(double data):` ####
Spec 1:
* double data Range contains positive values (valid)
* double data Range contains negative values (valid)
* double data Range contains decimal values (valid

Spec 2:
* double data Range is the same values (valid)

Spec 3:
* double data contains Max and Min Range values (valid)

Spec 4:
* double data contains out of range values (invalid)


### Input Partitions: DataUtilites Class Methods

#### `calculateColumnTotal(Values2D data, int column)` ####
Spec. 1
* data is null (Invalid)
* data is not null (Valid)

Spec. 2
* data can be empty (Valid)
* data can has one or more elements (Valid)

Spec. 3
* elements are negative numbers (Valid)
* elements are positive numbers (Valid)

Spec. 4
* column is negative index (Invalid)
* column is at least zero (Valid)


#### `calculateRowTotal(Values2D data, int row)` ####

Spec 1:
* a) Values2D data is not NULL (valid)
* b) Values2D data is NULL (not valid)

Spec 2:
* a) Values2D data is not empty (valid)
* b) Values2D data is empty (valid)

Spec 3:
* a) Row index within Values2D data range (valid)
* b) Row index negative & below Values2D data range (not valid)
* c) Row index greater than Values2D data range (not valid)

Spec 4:
* a) Values2D data contains negative values (valid)
* b) Values2D data contains positive values (valid)
* c) Values2D data contains negative & positive values (valid)

#### `createNumberArray(double[] data)` ####
Spec 1:
* a) double[] data is not NULL (valid)
* b) double[] data is NULL (not valid)

Spec 2:
* a) double[] data is not empty (valid)
* b) double[] data is empty (valid)

Spec 3:
* a) double[] data contains negative values (valid)
* b) double[] data contains positive values (valid)
* c) double[] data contains negative decimal values (valid)
* d) double[] data contains positive decimal values (valid)

Spec 4:
* a) double[] data contains lowest possible normal value (valid)
* b) double[] data contains maximum positive value (valid)

#### `createNumberArray2D(double[][] data):` ####

Spec 1:
* double[][] data is NULL (valid)
* double[][] data is not NULL (not valid) 

Spec 2:
* double[][] data is not empty (valid)
* double[][] data is empty (not valid) 

Spec 3:
* double[][] data contains negative values (valid)
* double[][] data contains positive values (valid)
* double[][] data contains negative decimal values (valid)
* double[][] data contains positive decimal values (valid)


# 3 Test cases developed


# 4 How the team work/effort was divided and managed

We first set up the system together as a group, to ensure we were on the same page and were all ready to start testing. We then decided to use pair testing again, by dividing the testing methods equally among each chair. It allowed us to maximize efficiency while still using each other to take the ease off problem solving. 

Pair #1 (Mushtaba/Parbir):

	This pair developed test cases for two Range Class:
		* constrain(double value)
		* getUpperBound()
	This pair developed test cases for three DataUtilities class:
		* calculateRowTotal(Values2D data, int row)
		* createNumberArray(double[] data)
		* createNumberArray2D(double [][[] data)

Pair #2 (Athul/Ahad)
	
	This pair developed test cases for three Range Class:
		* contain(double value)
		* getLength()
		* intersects(double lower, double upper)
	This pair developed test cases for two DataUtilities Class:
		* calculateColumnTotal(Values2D data, int column)
		* getCumulativePercentages(KeyedValues data)

Teamwork was managed by keeping strict deadlines, and maintaining team meetings. This allowed everyone to get their work done on time.

# 5 Difficulties encountered, challenges overcome, and lessons learned

One of the main lessons that we learned while working on the assignment was how efficient we were compared to the use of exploratory/manual functional testing in the previous assignment. With the use of JUnit and JMock, we were able to easily automate the testing procedure, saving us a bunch of time in the process. This was extremely evident when it came to the process of equivalent class testing. For instance, in the previous assignment, when it came to testing a certain partition of a particular method, the use of manual functional testing quickly became a tedious task, as we had to manually test each functionality to ensure its validity. However, JUnit sped up the process, as once we were able to partition our test cases using equivalence class testing, the automated testing process made it much easier to efficiently run our test cases, as well as create multiple test cases with ease within a partition when it came to boundary testing. Nonetheless, we did run into difficulties when it came to the setup of the environment for the use of both JUnit and JMock. Since we are using a GitHub repository, when we initially set up the java project we realized that we all had to import the external libraries in order to get JUnit and JMock to work correctly. However, once we pushed our changes, we started to run into difficulties as the libraries that each person imported were now also part of the java project, which caused errors when we tried to create/run tests using JUnit. Likewise, we overcame this difficulty by making sure that everyone removed the duplicate/unnecessary libraries from their local environment, which allowed everyone to run and create tests without errors.

# 6 Comments/feedback on the lab itself

We found that the setup part was quite confusing. We had a very difficult time using GitHub, where adding our own JarFiles didn’t work well with source control, therefore we had to avoid it. This took a large chunk of time, where no actual testing was done, just the set up itself took awhile, and took away from the learning process of the lab. As a result, we had to share our code as text files, which brought down the efficiency of pair testing as it was significantly harder to update and merge code. 

Overall, this external jar file issue could’ve been avoided and more time spent on testing itself would’ve been better from a learning aspect. Once we understood that we couldn’t use GitHub as with usual labs in other classes, we were able to complete the lab as intended. Additionally, the mocking test cases were well prepared, and gave us the opportunity to apply in class concepts, while challenging our knowledge. 

